{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. przygotowanie danych do transfer learningu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8sYm208EtFN"
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import statistics\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import os\n",
    "import pickle\n",
    "import torchvision.transforms as T\n",
    "import scipy.misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VghKGhCC90go",
    "outputId": "56db2c8a-43b1-46e2-f538-bf83cce9abd6"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "#sciagniecie danych z google drive\n",
    "!unzip \"/content/gdrive/MyDrive/Colab Notebooks/car_ims.zip\" -d \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frK9M3goOM_P",
    "outputId": "f8de415d-277b-4b95-9781-1078d0ea27d4"
   },
   "outputs": [],
   "source": [
    "#budowa funkcji, ktorej celem jest prawidlowe sciagniecie pliku zawierajacego \n",
    "#etykiety zbioru wykorzystanego do analizy \n",
    "def read_mat_to_df(file_path):\n",
    "    np_array= loadmat(file_path, matlab_compatible=False, simplify_cells=True, chars_as_strings=True)\n",
    "    df= pd.DataFrame(np_array['annotations'])\n",
    "    if 'class_names' in np_array:\n",
    "        class_names= list(np_array['class_names'])\n",
    "        df['class_name']= df['class'].map(dict(enumerate(class_names, start=1)))\n",
    "    # squeeze int-types\n",
    "    for c, t in df.dtypes.iteritems():\n",
    "        if t.kind == 'i':\n",
    "            df[c]= df[c].astype('int16')\n",
    "    if 'fname' in df.columns:\n",
    "        df['relative_im_path']= 'car_ims/0' + df['fname']\n",
    "        df.drop(columns=['fname'], inplace=True)\n",
    "    return df\n",
    "\n",
    "cars_full= read_mat_to_df('gdrive/MyDrive/cars_annos.mat')\n",
    "class_class_name_count=cars_full[['class','class_name']].value_counts().reset_index()\n",
    "class_to_name_dict=dict(zip(class_class_name_count['class'], class_class_name_count.class_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wjGb0gvOL2t"
   },
   "outputs": [],
   "source": [
    "#utworzenie kolumny w tabeli z etykietami, ktora bedzie wykorzystana do analizy jako zmienna objasniana\n",
    "cars_full['brand']=[class_name.split()[0] for class_name in cars_full['class_name'].tolist()]\n",
    "map_brand=cars_full['brand'].value_counts().reset_index()\n",
    "map_brand['class']=[x for x in range(1,len(map_brand)+1)]\n",
    "class_to_brand_dict=dict(zip(map_brand['index'], map_brand['class']))\n",
    "cars_full['class']=cars_full['brand'].map(class_to_brand_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7h8fR6RpOSF0"
   },
   "outputs": [],
   "source": [
    "# zbudowanie funkcji, ktorej celem bedzie ekstrakcja danych. Funkcja ta posiada wiele argumentow, ktore\n",
    "# umozliwiaja uzytkownikowi modyfikacje obserwacji\n",
    "# cropped - przycinanie zdjecia aby wynikiem byl wylacznie samochod\n",
    "# white_black - wybranie wymiarow zdjecia, czarne==True, biale==False\n",
    "# sub_sample - wybranie ilosci zdjec poddanych ekstracji i pre-processingu\n",
    "# image_dim_change - bool parametr, ktory uzytkownik moze uzyc w sytuacji checi zmienienia wymiarow zdjecia\n",
    "# image_dim_change_val - parametr, ktory oznajmia jakie wymiary zdjecie powinno posiadac\n",
    "# final_data - zastosowanie wyrownania histogramy oraz podzielenia wektoru ze zdjeciem przez 255 w sytuacji, gdy \n",
    "# parametr bedzie rownal sie z True\n",
    "# wynikiem funkcji sa zdjecia oraz ich wymiary\n",
    "\n",
    "def loop_for_car_images(df,white_black=True,sub_sample=None,\n",
    "                        cropped=True, image_stand=False,\n",
    "                        image_stand_val=[100,100],final_data=False):\n",
    "    df1=df.copy()\n",
    "    images=[]\n",
    "    i=0\n",
    "    images_dim=[]\n",
    "    for index,row in df1.iterrows():\n",
    "        i+=1\n",
    "        path=os.path.join(df['relative_im_path'][index])\n",
    "        image = Image.open(path)\n",
    "        if len(np.array(image).shape)==3 and white_black==True:\n",
    "            image=image.convert('L')\n",
    "        image_array=np.array(image)\n",
    "        if len(image_array.shape)<3 and white_black==False:\n",
    "            image_array=cv2.merge((image_array,image_array,image_array))\n",
    "        if cropped:\n",
    "            image_array=image_array[row['bbox_y1']:row['bbox_y2'],row['bbox_x1']:row['bbox_x2']]\n",
    "        if image_stand:\n",
    "            image_array = Image.fromarray(image_array)\n",
    "            transform = T.Resize(size = (image_stand_val[0],image_stand_val[1]))\n",
    "            image_array = transform(image_array)\n",
    "            image_array=np.array(image_array)\n",
    "        if final_data:\n",
    "            image_array=image_array/255\n",
    "\n",
    "        images.append(image_array)\n",
    "        images_dim.append(image_array.shape)\n",
    "        if i%1000==0:\n",
    "            print(f'{i} photos have been uploaded')\n",
    "    return images, images_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wiFzbCXPOTE8",
    "outputId": "eaa014b8-df4e-4c09-81d6-61c2e48fc771"
   },
   "outputs": [],
   "source": [
    "#sciaganie danych oraz ich wymiarow\n",
    "images,_=loop_for_car_images(cars_full,white_black=False,image_stand=True,\n",
    "                              image_stand_val=[200,200],final_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mgSK-OhOkMj"
   },
   "outputs": [],
   "source": [
    "# podzial danych na zbior treningowy, walidacyjny oraz testowy\n",
    "X=images\n",
    "y=cars_full['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=5,stratify=y)\n",
    "X_val, X_test, y_val, y_test =train_test_split(X_test, y_test, test_size = 0.5,random_state=20,stratify=y_test)\n",
    "del images, _, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUxBClCcOkX4"
   },
   "outputs": [],
   "source": [
    "# utworzenie funkcji, ktora stosowac bedzie na danych metody data augmentation\n",
    "augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  tf.keras.layers.RandomRotation(0.2,fill_mode='constant',seed=1),\n",
    "])\n",
    "def data_aug(X,y,how_much_total,show=False):\n",
    "    data_val_count=y.value_counts().reset_index()\n",
    "    low_cat=data_val_count[data_val_count['class']<how_much_total]\n",
    "    low_cat.columns=['class','count']\n",
    "    images_aug=list(X.copy())\n",
    "    labels_aug=list(y.copy())\n",
    "    df_y=pd.DataFrame(y).reset_index()\n",
    "    df_y.columns=['previous index','y']\n",
    "    for _,low_cat_row in low_cat.iterrows():\n",
    "        how_much_aug=how_much_total-low_cat_row['count']\n",
    "        df_temp=df_y[df_y['y']==low_cat_row['class']]\n",
    "        i=0\n",
    "        show1=False\n",
    "        if show==True:\n",
    "            show1=True\n",
    "        while i<how_much_aug:\n",
    "            for index,row in df_temp.iterrows():\n",
    "                #image_to_aug=X[index].copy()[..., np.newaxis]\n",
    "                image_to_aug=X[index].copy()\n",
    "                aug_image=augmentation(image_to_aug)\n",
    "                if show1:\n",
    "                    print(class_to_name_dict.get(low_cat_row['class']))\n",
    "                    plt.figure(figsize=(15,10))\n",
    "                    plt.imshow(image_to_aug)\n",
    "                    plt.show()\n",
    "                    plt.figure(figsize=(15,10))\n",
    "                    plt.imshow(aug_image)\n",
    "                    plt.show()\n",
    "                    show1=False\n",
    "                images_aug.append(aug_image)\n",
    "                labels_aug.append(low_cat_row['class'])\n",
    "                i+=1\n",
    "                if i>=how_much_aug:\n",
    "                    break\n",
    "    print('Done!')\n",
    "    return images_aug, labels_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5X17VoNOkdt",
    "outputId": "fe29d84e-7e0f-49ab-8348-18ae95c2e8d6"
   },
   "outputs": [],
   "source": [
    "# zastosowanie data augmentation na danych treningowych\n",
    "X_train, y_train=data_aug(X_train,y_train,how_much_total=250,show=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nVQXyFqtOkgX"
   },
   "outputs": [],
   "source": [
    "# zmienienie klasy danych aby mogly byc uzyte do budowy modeli splotowych sieci neuronowych\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "X_val=np.array(X_val)\n",
    "X_test=np.array(X_test)\n",
    "y_train=np.array(y_train)\n",
    "y_val=np.array(y_val)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "\n",
    "y_train=tf.keras.utils.to_categorical(y_train)\n",
    "y_val=tf.keras.utils.to_categorical(y_val)\n",
    "y_test=tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPSqr5VU5f-R"
   },
   "outputs": [],
   "source": [
    "# zapisanie dancyh w formie pickle\n",
    "\n",
    "import pickle\n",
    "pick_insert = open('gdrive/My Drive/X_train_color.pkl','wb')\n",
    "pickle.dump(X_train, pick_insert)\n",
    "pick_insert.close()\n",
    "pick_insert = open('gdrive/My Drive/X_val_color.pkl','wb')\n",
    "pickle.dump(X_val, pick_insert)\n",
    "pick_insert.close()\n",
    "pick_insert = open('gdrive/My Drive/X_test_color.pkl','wb')\n",
    "pickle.dump(X_test, pick_insert)\n",
    "pick_insert.close()\n",
    "pick_insert = open('gdrive/My Drive/y_train_color.pkl','wb')\n",
    "pickle.dump(y_train, pick_insert)\n",
    "pick_insert.close()\n",
    "pick_insert = open('gdrive/My Drive/y_val_color.pkl','wb')\n",
    "pickle.dump(y_val, pick_insert)\n",
    "pick_insert.close()\n",
    "pick_insert = open('gdrive/My Drive/y_test_color.pkl','wb')\n",
    "pickle.dump(y_test, pick_insert)\n",
    "pick_insert.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "history_visible": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
